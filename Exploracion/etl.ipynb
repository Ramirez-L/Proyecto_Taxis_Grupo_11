{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DateType, DecimalType, IntegerType,FloatType\n",
    "import pandas as pd \n",
    "# Build SparkSession\n",
    "#spark = SparkSession.builder.master(\"local[*]\").appName(\"ETL Pipeline\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/13 10:28:32 WARN Utils: Your hostname, LAPTOP-GOF4EGS4 resolves to a loopback address: 127.0.1.1; using 172.17.204.25 instead (on interface eth0)\n",
      "22/07/13 10:28:32 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/13 10:28:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "master = \"spark://192.53.165.168:7077\"\n",
    "master = \"local\"\n",
    "#        .master(master)\\\n",
    "\n",
    "# SparkSession\n",
    "#                 .builder\n",
    "#                 .appName('example-pyspark-read-and-write-from-hive')\n",
    "#                 .config(\"hive.metastore.uris\", \"thrift://localhost:9083\", conf=SparkConf())\n",
    "#                 .enableHiveSupport()\n",
    "#                 .getOrCreate()\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "        .appName('taxis')\\\n",
    "        .master(master)\\\n",
    "        .config(\"hive.metastore.uris\", \"thrift://192.53.165.168:9083\", conf=SparkConf())\\\n",
    "        .enableHiveSupport()\\\n",
    "        .getOrCreate()\n",
    "# Set Logging Level to WARN\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.csv(\"hdfs://\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.17.204.25:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://192.53.165.168:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>taxis</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f16b4fad5b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.getActiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:============================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+--------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Tiempo_Viaje_s|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+--------------+\n",
      "|       1| 2017-12-31 19:21:05|  2017-12-31 19:24:23|              1|          0.5|         1|                 N|          41|          24|           2|        4.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         5.8|                 0.0|         198.0|\n",
      "|       1| 2017-12-31 19:44:55|  2017-12-31 20:03:05|              1|          2.7|         1|                 N|         239|         140|           2|       14.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        15.3|                 0.0|        1090.0|\n",
      "|       1| 2017-12-31 19:08:26|  2017-12-31 19:14:21|              2|          0.8|         1|                 N|         262|         141|           1|        6.0|  0.5|    0.5|       1.0|         0.0|                  0.3|         8.3|                 0.0|         355.0|\n",
      "|       1| 2017-12-31 19:20:22|  2017-12-31 19:52:51|              1|         10.2|         1|                 N|         140|         257|           2|       33.5|  0.5|    0.5|       0.0|         0.0|                  0.3|        34.8|                 0.0|        1949.0|\n",
      "|       1| 2017-12-31 19:09:18|  2017-12-31 19:27:06|              2|          2.5|         1|                 N|         246|         239|           1|       12.5|  0.5|    0.5|      2.75|         0.0|                  0.3|       16.55|                 0.0|        1068.0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_taxis=spark.read.option(\"header\", \"true\").parquet(\"../Data/Taxis.parquet\")\n",
    "df_taxis.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|Id_Vendor|         Vendor_Name|\n",
      "+---------+--------------------+\n",
      "|        1|Creative Mobiles ...|\n",
      "|        2|       VeriFone Inc.|\n",
      "+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Vendor_columns=[\"Id_Vendor\",\"Vendor_Name\"]\n",
    "Vendor=[(1,\"Creative Mobiles Technologies\"),(2,\"VeriFone Inc.\")]\n",
    "df_vendor=spark.createDataFrame(Vendor,Vendor_columns)\n",
    "df_vendor.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|Id_Rate|           Rate_Name|\n",
      "+-------+--------------------+\n",
      "|      1|       Standard rate|\n",
      "|      2|                 JFK|\n",
      "|      3|              Newark|\n",
      "|      4|Nassau or Westche...|\n",
      "|      5|     Negotiated fare|\n",
      "|      6|          Group ride|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Rate_columns=['Id_Rate', 'Rate_Name']\n",
    "Rate=[\n",
    "    (1,\"Standard rate\"),\n",
    "    (2,\"JFK\"),\n",
    "    (3,\"Newark\"),\n",
    "    (4,\"Nassau or Westchester\"),\n",
    "    (5,\"Negotiated fare\"),\n",
    "    (6,\"Group ride\")]\n",
    "\n",
    "df_rate=spark.createDataFrame(Rate,Rate_columns)\n",
    "df_rate.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|Id_Payment|Payment_type|\n",
      "+----------+------------+\n",
      "|         1| Credit card|\n",
      "|         2|        Cash|\n",
      "|         3|   No charge|\n",
      "|         4|     Dispute|\n",
      "|         5|     Unknown|\n",
      "|         6| Voided trip|\n",
      "+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Payment_columns=['Id_Payment', 'Payment_type']\n",
    "Payment= [\n",
    "    (1,\"Credit card\"),\n",
    "    (2,\"Cash\"),\n",
    "    (3,\"No charge\"),\n",
    "    (4,\"Dispute\"),\n",
    "    (5,\"Unknown\"),\n",
    "    (6,\"Voided trip\")]\n",
    "df_payment=spark.createDataFrame(Payment,Payment_columns)\n",
    "df_payment.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+---------+----------+\n",
      "|ID_Borough|      Borough|  Latitud|  Longitud|\n",
      "+----------+-------------+---------+----------+\n",
      "|         1|    Manhattan|40.776676| -73.97132|\n",
      "|         2|     Brooklyn|    40.65|    -73.95|\n",
      "|         3|        Bronx|40.837048| -73.86543|\n",
      "|         4|       Queens|40.742054| -73.76942|\n",
      "|         5|Staten Island| 40.57902|-74.151535|\n",
      "+----------+-------------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Borough_columns=[\"ID_Borough\",\"Borough\",\"Latitud\",\"Longitud\"]\n",
    "Borough = [\n",
    "    (1,\"Manhattan\",40.776676,-73.971321),\n",
    "    (2,\"Brooklyn\",40.650002,-73.949997),\n",
    "    (3,\"Bronx\",40.837048,-73.865433),\n",
    "    (4,\"Queens\",40.742054,-73.769417),\n",
    "    (5,\"Staten Island\",40.579021,-74.151535),\n",
    "]\n",
    "Borough_schema = StructType([ \n",
    "    StructField(\"ID_Borough\",IntegerType(),True), \n",
    "    StructField(\"Borough\",StringType(),True), \n",
    "    StructField(\"Latitud\",FloatType(),True), \n",
    "    StructField(\"Longitud\", FloatType(), True), \n",
    "])\n",
    "df_borough=spark.createDataFrame(data=Borough,schema=Borough_schema).cache()\n",
    "df_borough.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/mangoru/Proyecto_Taxis_Grupo_11/Exploracion/etl.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mangoru/Proyecto_Taxis_Grupo_11/Exploracion/etl.ipynb#ch0000009vscode-remote?line=0'>1</a>\u001b[0m location_schema \u001b[39m=\u001b[39m StructType([ \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mangoru/Proyecto_Taxis_Grupo_11/Exploracion/etl.ipynb#ch0000009vscode-remote?line=1'>2</a>\u001b[0m     StructField(\u001b[39m\"\u001b[39m\u001b[39mLocationID\u001b[39m\u001b[39m\"\u001b[39m,IntegerType(),\u001b[39mTrue\u001b[39;00m), \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mangoru/Proyecto_Taxis_Grupo_11/Exploracion/etl.ipynb#ch0000009vscode-remote?line=2'>3</a>\u001b[0m     StructField(\u001b[39m\"\u001b[39m\u001b[39mBorough\u001b[39m\u001b[39m\"\u001b[39m,StringType(),\u001b[39mTrue\u001b[39;00m), \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mangoru/Proyecto_Taxis_Grupo_11/Exploracion/etl.ipynb#ch0000009vscode-remote?line=3'>4</a>\u001b[0m     StructField(\u001b[39m\"\u001b[39m\u001b[39mZone\u001b[39m\u001b[39m\"\u001b[39m,StringType(),\u001b[39mTrue\u001b[39;00m), \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mangoru/Proyecto_Taxis_Grupo_11/Exploracion/etl.ipynb#ch0000009vscode-remote?line=4'>5</a>\u001b[0m     StructField(\u001b[39m\"\u001b[39m\u001b[39mservice_zone\u001b[39m\u001b[39m\"\u001b[39m, StringType(), \u001b[39mTrue\u001b[39;00m), \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mangoru/Proyecto_Taxis_Grupo_11/Exploracion/etl.ipynb#ch0000009vscode-remote?line=5'>6</a>\u001b[0m ])\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mangoru/Proyecto_Taxis_Grupo_11/Exploracion/etl.ipynb#ch0000009vscode-remote?line=6'>7</a>\u001b[0m data_location\u001b[39m=\u001b[39mspark\u001b[39m.\u001b[39mread\u001b[39m.\u001b[39moption(\u001b[39m\"\u001b[39m\u001b[39mheader\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtrue\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mcsv(\u001b[39m\"\u001b[39m\u001b[39m../taxi+_zone_lookup.csv\u001b[39m\u001b[39m\"\u001b[39m,schema\u001b[39m=\u001b[39mlocation_schema)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mangoru/Proyecto_Taxis_Grupo_11/Exploracion/etl.ipynb#ch0000009vscode-remote?line=7'>8</a>\u001b[0m data_location\u001b[39m.\u001b[39mshow(\u001b[39m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "location_schema = StructType([ \n",
    "    StructField(\"LocationID\",IntegerType(),True), \n",
    "    StructField(\"Borough\",StringType(),True), \n",
    "    StructField(\"Zone\",StringType(),True), \n",
    "    StructField(\"service_zone\", StringType(), True), \n",
    "])\n",
    "data_location=spark.read.option(\"header\", \"true\").csv(\"../taxi+_zone_lookup.csv\",schema=location_schema)\n",
    "data_location.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+------------+\n",
      "|LocationID|ID_Borough|                Zone|service_zone|\n",
      "+----------+----------+--------------------+------------+\n",
      "|         2|         4|         Jamaica Bay|   Boro Zone|\n",
      "|         3|         3|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|         1|       Alphabet City| Yellow Zone|\n",
      "|         5|         5|       Arden Heights|   Boro Zone|\n",
      "|         6|         5|Arrochar/Fort Wad...|   Boro Zone|\n",
      "+----------+----------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_location = data_location.join(df_borough,on='Borough',how='left').drop(\"Borough\", \"Latitud\", \"Longitud\")\n",
    "data_location=data_location.dropna()[[\"LocationID\", \"ID_Borough\", \"Zone\", \"service_zone\"]]\n",
    "data_location.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabla_calendario(start='2018-01-01', end='2018-12-31'):\n",
    "    df = pd.DataFrame({\"Date\": pd.date_range(start, end)})\n",
    "    df[\"Year\"] = df.Date.dt.year\n",
    "    df[\"Month\"] = df.Date.dt.month\n",
    "    df[\"Day\"] = df.Date.dt.day\n",
    "    df[\"Week\"] = df.Date.dt.isocalendar().week\n",
    "    df[\"Quarter\"] = df.Date.dt.quarter\n",
    "    df[\"Year_half\"] = (df.Quarter + 1) // 2\n",
    "    df[\"Weekday\"] = df.Date.dt.day_of_week\n",
    "    return df\n",
    "# calendario=spark.createDataFrame(tabla_calendario(start='2018-01-01', end='2018-12-31'))\n",
    "# calendario.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calendario=tabla_calendario(start='2018-01-01', end='2018-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "DATABASE_LOCATION='hive://192.53.165.168:10000/TaxisDB'\n",
    "# DATABASE_LOCATION=\"apachehive:///?Server=127.0.0.1&;Port=10000&TransportMode=BINARY\"\n",
    "engine = sqlalchemy.create_engine(DATABASE_LOCATION,echo=True)\n",
    "cursor = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-13 11:26:34,633 INFO sqlalchemy.engine.Engine create database taxisdb\n",
      "2022-07-13 11:26:34,641 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2022-07-13 11:26:36,139 INFO sqlalchemy.engine.Engine COMMIT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x7eff0c9bf970>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(\"create database taxisdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "DATABASE_LOCATION='hive://192.53.165.168:10000/taxisdb'\n",
    "# DATABASE_LOCATION=\"apachehive:///?Server=127.0.0.1&;Port=10000&TransportMode=BINARY\"\n",
    "engine = sqlalchemy.create_engine(DATABASE_LOCATION,echo=True)\n",
    "cursor = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-13 14:00:12,351 INFO sqlalchemy.engine.Engine show databases\n",
      "2022-07-13 14:00:12,354 INFO sqlalchemy.engine.Engine [raw sql] {}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('default',), ('taxisdb',)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(\"show databases\").all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-13 14:00:15,299 INFO sqlalchemy.engine.Engine \n",
      "create table if not exists location(\n",
      "    LocationID int,\n",
      "    Borough string,\n",
      "    Zone string,\n",
      "    service_zone string,\n",
      "    primary key(LocationID) disable novalidate \n",
      ")\n",
      "\n",
      "2022-07-13 14:00:15,301 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2022-07-13 14:00:15,619 INFO sqlalchemy.engine.Engine COMMIT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x7efecbf83760>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"\"\"\n",
    "create table if not exists location(\n",
    "    LocationID int,\n",
    "    Borough string,\n",
    "    Zone string,\n",
    "    service_zone string,\n",
    "    primary key(LocationID) disable novalidate \n",
    ")\n",
    "\"\"\"\n",
    "cursor.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationID</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Zone</th>\n",
       "      <th>service_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>261</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>World Trade Center</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>262</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Yorkville East</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>263</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Yorkville West</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>264</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NV</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>265</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     LocationID        Borough                     Zone service_zone\n",
       "0             1            EWR           Newark Airport          EWR\n",
       "1             2         Queens              Jamaica Bay    Boro Zone\n",
       "2             3          Bronx  Allerton/Pelham Gardens    Boro Zone\n",
       "3             4      Manhattan            Alphabet City  Yellow Zone\n",
       "4             5  Staten Island            Arden Heights    Boro Zone\n",
       "..          ...            ...                      ...          ...\n",
       "260         261      Manhattan       World Trade Center  Yellow Zone\n",
       "261         262      Manhattan           Yorkville East  Yellow Zone\n",
       "262         263      Manhattan           Yorkville West  Yellow Zone\n",
       "263         264        Unknown                       NV          NaN\n",
       "264         265        Unknown                      NaN          NaN\n",
       "\n",
       "[265 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_location=pd.read_csv(\"../taxi+_zone_lookup.csv\")\n",
    "df_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-13 14:00:42,956 INFO sqlalchemy.engine.Engine DESCRIBE location\n",
      "2022-07-13 14:00:42,959 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2022-07-13 14:00:43,627 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2022-07-13 14:00:43,639 INFO sqlalchemy.engine.Engine INSERT INTO TABLE `location` VALUES (%(LocationID)s, %(Borough)s, %(Zone)s, %(service_zone)s)\n",
      "2022-07-13 14:00:43,641 INFO sqlalchemy.engine.Engine [dialect b'hive'+b'thrift' does not support caching 0.00401s] ({'LocationID': 1, 'Borough': 'EWR', 'Zone': 'Newark Airport', 'service_zone': 'EWR'}, {'LocationID': 2, 'Borough': 'Queens', 'Zone': 'Jamaica Bay', 'service_zone': 'Boro Zone'}, {'LocationID': 3, 'Borough': 'Bronx', 'Zone': 'Allerton/Pelham Gardens', 'service_zone': 'Boro Zone'}, {'LocationID': 4, 'Borough': 'Manhattan', 'Zone': 'Alphabet City', 'service_zone': 'Yellow Zone'}, {'LocationID': 5, 'Borough': 'Staten Island', 'Zone': 'Arden Heights', 'service_zone': 'Boro Zone'}, {'LocationID': 6, 'Borough': 'Staten Island', 'Zone': 'Arrochar/Fort Wadsworth', 'service_zone': 'Boro Zone'}, {'LocationID': 7, 'Borough': 'Queens', 'Zone': 'Astoria', 'service_zone': 'Boro Zone'}, {'LocationID': 8, 'Borough': 'Queens', 'Zone': 'Astoria Park', 'service_zone': 'Boro Zone'}  ... displaying 10 of 265 total bound parameter sets ...  {'LocationID': 264, 'Borough': 'Unknown', 'Zone': 'NV', 'service_zone': None}, {'LocationID': 265, 'Borough': 'Unknown', 'Zone': None, 'service_zone': None})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mangoru/.local/lib/python3.8/site-packages/pandas/io/sql.py:857: SAWarning: Dialect b'hive':b'thrift' will not make use of SQL compilation caching as it does not set the 'supports_statement_cache' attribute to ``True``.  This can have significant performance implications including some performance degradations in comparison to prior SQLAlchemy versions.  Dialect maintainers should seek to set this attribute to True after appropriate development and testing for SQLAlchemy 1.4 caching support.   Alternatively, this attribute may be set to False which will disable this warning. (Background on this error at: https://sqlalche.me/e/14/cprf)\n",
      "  result = conn.execute(self.table.insert(), data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-13 14:00:46,053 INFO sqlalchemy.engine.Engine ROLLBACK\n"
     ]
    },
    {
     "ename": "ProgrammingError",
     "evalue": "(pyhive.exc.ProgrammingError) No result set\n[SQL: INSERT INTO TABLE `location` VALUES (%(LocationID)s, %(Borough)s, %(Zone)s, %(service_zone)s)]\n[parameters: ({'LocationID': 1, 'Borough': 'EWR', 'Zone': 'Newark Airport', 'service_zone': 'EWR'}, {'LocationID': 2, 'Borough': 'Queens', 'Zone': 'Jamaica Bay', 'service_zone': 'Boro Zone'}, {'LocationID': 3, 'Borough': 'Bronx', 'Zone': 'Allerton/Pelham Gardens', 'service_zone': 'Boro Zone'}, {'LocationID': 4, 'Borough': 'Manhattan', 'Zone': 'Alphabet City', 'service_zone': 'Yellow Zone'}, {'LocationID': 5, 'Borough': 'Staten Island', 'Zone': 'Arden Heights', 'service_zone': 'Boro Zone'}, {'LocationID': 6, 'Borough': 'Staten Island', 'Zone': 'Arrochar/Fort Wadsworth', 'service_zone': 'Boro Zone'}, {'LocationID': 7, 'Borough': 'Queens', 'Zone': 'Astoria', 'service_zone': 'Boro Zone'}, {'LocationID': 8, 'Borough': 'Queens', 'Zone': 'Astoria Park', 'service_zone': 'Boro Zone'}  ... displaying 10 of 265 total bound parameter sets ...  {'LocationID': 264, 'Borough': 'Unknown', 'Zone': 'NV', 'service_zone': None}, {'LocationID': 265, 'Borough': 'Unknown', 'Zone': None, 'service_zone': None})]\n(Background on this error at: https://sqlalche.me/e/14/f405)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py:1799\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1798\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1799\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_executemany(\n\u001b[1;32m   1800\u001b[0m             cursor, statement, parameters, context\n\u001b[1;32m   1801\u001b[0m         )\n\u001b[1;32m   1802\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m parameters \u001b[39mand\u001b[39;00m context\u001b[39m.\u001b[39mno_parameters:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py:729\u001b[0m, in \u001b[0;36mDefaultDialect.do_executemany\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_executemany\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 729\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecutemany(statement, parameters)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyhive/common.py:91\u001b[0m, in \u001b[0;36mDBAPICursor.executemany\u001b[0;34m(self, operation, seq_of_parameters)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_STATE_FINISHED:\n\u001b[0;32m---> 91\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fetch_more()\n\u001b[1;32m     92\u001b[0m \u001b[39mif\u001b[39;00m seq_of_parameters:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyhive/hive.py:470\u001b[0m, in \u001b[0;36mCursor._fetch_more\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_operationHandle\u001b[39m.\u001b[39mhasResultSet:\n\u001b[0;32m--> 470\u001b[0m     \u001b[39mraise\u001b[39;00m ProgrammingError(\u001b[39m\"\u001b[39m\u001b[39mNo result set\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    471\u001b[0m req \u001b[39m=\u001b[39m ttypes\u001b[39m.\u001b[39mTFetchResultsReq(\n\u001b[1;32m    472\u001b[0m     operationHandle\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_operationHandle,\n\u001b[1;32m    473\u001b[0m     orientation\u001b[39m=\u001b[39mttypes\u001b[39m.\u001b[39mTFetchOrientation\u001b[39m.\u001b[39mFETCH_NEXT,\n\u001b[1;32m    474\u001b[0m     maxRows\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39marraysize,\n\u001b[1;32m    475\u001b[0m )\n",
      "\u001b[0;31mProgrammingError\u001b[0m: No result set",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/home/mangoru/Proyecto_Taxis_Grupo_11/Exploracion/etl.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mangoru/Proyecto_Taxis_Grupo_11/Exploracion/etl.ipynb#ch0000021vscode-remote?line=0'>1</a>\u001b[0m \u001b[39m# try:\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mangoru/Proyecto_Taxis_Grupo_11/Exploracion/etl.ipynb#ch0000021vscode-remote?line=1'>2</a>\u001b[0m df_location\u001b[39m.\u001b[39;49mto_sql(\u001b[39m\"\u001b[39;49m\u001b[39mlocation\u001b[39;49m\u001b[39m\"\u001b[39;49m, engine, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, if_exists\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mappend\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py:2951\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[0;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   2794\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2795\u001b[0m \u001b[39mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[1;32m   2796\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2947\u001b[0m \u001b[39m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[1;32m   2948\u001b[0m \u001b[39m\"\"\"\u001b[39;00m  \u001b[39m# noqa:E501\u001b[39;00m\n\u001b[1;32m   2949\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mimport\u001b[39;00m sql\n\u001b[0;32m-> 2951\u001b[0m \u001b[39mreturn\u001b[39;00m sql\u001b[39m.\u001b[39;49mto_sql(\n\u001b[1;32m   2952\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2953\u001b[0m     name,\n\u001b[1;32m   2954\u001b[0m     con,\n\u001b[1;32m   2955\u001b[0m     schema\u001b[39m=\u001b[39;49mschema,\n\u001b[1;32m   2956\u001b[0m     if_exists\u001b[39m=\u001b[39;49mif_exists,\n\u001b[1;32m   2957\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   2958\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[1;32m   2959\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m   2960\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   2961\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m   2962\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/sql.py:697\u001b[0m, in \u001b[0;36mto_sql\u001b[0;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(frame, DataFrame):\n\u001b[1;32m    693\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    694\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m'\u001b[39m\u001b[39m argument should be either a Series or a DataFrame\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    695\u001b[0m     )\n\u001b[0;32m--> 697\u001b[0m \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39;49mto_sql(\n\u001b[1;32m    698\u001b[0m     frame,\n\u001b[1;32m    699\u001b[0m     name,\n\u001b[1;32m    700\u001b[0m     if_exists\u001b[39m=\u001b[39;49mif_exists,\n\u001b[1;32m    701\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m    702\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[1;32m    703\u001b[0m     schema\u001b[39m=\u001b[39;49mschema,\n\u001b[1;32m    704\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m    705\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    706\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    707\u001b[0m     engine\u001b[39m=\u001b[39;49mengine,\n\u001b[1;32m    708\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mengine_kwargs,\n\u001b[1;32m    709\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/sql.py:1739\u001b[0m, in \u001b[0;36mSQLDatabase.to_sql\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[1;32m   1727\u001b[0m sql_engine \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[1;32m   1729\u001b[0m table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_table(\n\u001b[1;32m   1730\u001b[0m     frame\u001b[39m=\u001b[39mframe,\n\u001b[1;32m   1731\u001b[0m     name\u001b[39m=\u001b[39mname,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1736\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[1;32m   1737\u001b[0m )\n\u001b[0;32m-> 1739\u001b[0m total_inserted \u001b[39m=\u001b[39m sql_engine\u001b[39m.\u001b[39;49minsert_records(\n\u001b[1;32m   1740\u001b[0m     table\u001b[39m=\u001b[39;49mtable,\n\u001b[1;32m   1741\u001b[0m     con\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnectable,\n\u001b[1;32m   1742\u001b[0m     frame\u001b[39m=\u001b[39;49mframe,\n\u001b[1;32m   1743\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   1744\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   1745\u001b[0m     schema\u001b[39m=\u001b[39;49mschema,\n\u001b[1;32m   1746\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m   1747\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m   1748\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mengine_kwargs,\n\u001b[1;32m   1749\u001b[0m )\n\u001b[1;32m   1751\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_case_sensitive(name\u001b[39m=\u001b[39mname, schema\u001b[39m=\u001b[39mschema)\n\u001b[1;32m   1752\u001b[0m \u001b[39mreturn\u001b[39;00m total_inserted\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/sql.py:1332\u001b[0m, in \u001b[0;36mSQLAlchemyEngine.insert_records\u001b[0;34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001b[0m\n\u001b[1;32m   1330\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39minf cannot be used with MySQL\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   1331\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1332\u001b[0m     \u001b[39mraise\u001b[39;00m err\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/sql.py:1322\u001b[0m, in \u001b[0;36mSQLAlchemyEngine.insert_records\u001b[0;34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msqlalchemy\u001b[39;00m \u001b[39mimport\u001b[39;00m exc\n\u001b[1;32m   1321\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1322\u001b[0m     \u001b[39mreturn\u001b[39;00m table\u001b[39m.\u001b[39;49minsert(chunksize\u001b[39m=\u001b[39;49mchunksize, method\u001b[39m=\u001b[39;49mmethod)\n\u001b[1;32m   1323\u001b[0m \u001b[39mexcept\u001b[39;00m exc\u001b[39m.\u001b[39mSQLAlchemyError \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m   1324\u001b[0m     \u001b[39m# GH34431\u001b[39;00m\n\u001b[1;32m   1325\u001b[0m     \u001b[39m# https://stackoverflow.com/a/67358288/6067848\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m(1054, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown column \u001b[39m\u001b[39m'\u001b[39m\u001b[39minf(e0)?\u001b[39m\u001b[39m'\u001b[39m\u001b[39m in \u001b[39m\u001b[39m'\u001b[39m\u001b[39mfield list\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m))(?#\u001b[39m\n\u001b[1;32m   1327\u001b[0m \u001b[39m    )|inf can not be used with MySQL\u001b[39m\u001b[39m\"\"\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/sql.py:950\u001b[0m, in \u001b[0;36mSQLTable.insert\u001b[0;34m(self, chunksize, method)\u001b[0m\n\u001b[1;32m    947\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    949\u001b[0m chunk_iter \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m(arr[start_i:end_i] \u001b[39mfor\u001b[39;00m arr \u001b[39min\u001b[39;00m data_list))\n\u001b[0;32m--> 950\u001b[0m num_inserted \u001b[39m=\u001b[39m exec_insert(conn, keys, chunk_iter)\n\u001b[1;32m    951\u001b[0m \u001b[39mif\u001b[39;00m num_inserted \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    952\u001b[0m     total_inserted \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/sql.py:857\u001b[0m, in \u001b[0;36mSQLTable._execute_insert\u001b[0;34m(self, conn, keys, data_iter)\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    846\u001b[0m \u001b[39mExecute SQL statement inserting data\u001b[39;00m\n\u001b[1;32m    847\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[39m   Each item contains a list of values to be inserted\u001b[39;00m\n\u001b[1;32m    855\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    856\u001b[0m data \u001b[39m=\u001b[39m [\u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(keys, row)) \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m data_iter]\n\u001b[0;32m--> 857\u001b[0m result \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mexecute(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtable\u001b[39m.\u001b[39;49minsert(), data)\n\u001b[1;32m    858\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mrowcount\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py:1306\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   1302\u001b[0m     util\u001b[39m.\u001b[39mraise_(\n\u001b[1;32m   1303\u001b[0m         exc\u001b[39m.\u001b[39mObjectNotExecutableError(statement), replace_context\u001b[39m=\u001b[39merr\n\u001b[1;32m   1304\u001b[0m     )\n\u001b[1;32m   1305\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1306\u001b[0m     \u001b[39mreturn\u001b[39;00m meth(\u001b[39mself\u001b[39;49m, multiparams, params, _EMPTY_EXECUTION_OPTS)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py:332\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[0;34m(self, connection, multiparams, params, execution_options, _force)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_execute_on_connection\u001b[39m(\n\u001b[1;32m    329\u001b[0m     \u001b[39mself\u001b[39m, connection, multiparams, params, execution_options, _force\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    330\u001b[0m ):\n\u001b[1;32m    331\u001b[0m     \u001b[39mif\u001b[39;00m _force \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupports_execution:\n\u001b[0;32m--> 332\u001b[0m         \u001b[39mreturn\u001b[39;00m connection\u001b[39m.\u001b[39;49m_execute_clauseelement(\n\u001b[1;32m    333\u001b[0m             \u001b[39mself\u001b[39;49m, multiparams, params, execution_options\n\u001b[1;32m    334\u001b[0m         )\n\u001b[1;32m    335\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    336\u001b[0m         \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mObjectNotExecutableError(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py:1498\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[0;34m(self, elem, multiparams, params, execution_options)\u001b[0m\n\u001b[1;32m   1486\u001b[0m compiled_cache \u001b[39m=\u001b[39m execution_options\u001b[39m.\u001b[39mget(\n\u001b[1;32m   1487\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcompiled_cache\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_compiled_cache\n\u001b[1;32m   1488\u001b[0m )\n\u001b[1;32m   1490\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39m_compile_w_cache(\n\u001b[1;32m   1491\u001b[0m     dialect\u001b[39m=\u001b[39mdialect,\n\u001b[1;32m   1492\u001b[0m     compiled_cache\u001b[39m=\u001b[39mcompiled_cache,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1496\u001b[0m     linting\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\u001b[39m.\u001b[39mcompiler_linting \u001b[39m|\u001b[39m compiler\u001b[39m.\u001b[39mWARN_LINTING,\n\u001b[1;32m   1497\u001b[0m )\n\u001b[0;32m-> 1498\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_context(\n\u001b[1;32m   1499\u001b[0m     dialect,\n\u001b[1;32m   1500\u001b[0m     dialect\u001b[39m.\u001b[39;49mexecution_ctx_cls\u001b[39m.\u001b[39;49m_init_compiled,\n\u001b[1;32m   1501\u001b[0m     compiled_sql,\n\u001b[1;32m   1502\u001b[0m     distilled_params,\n\u001b[1;32m   1503\u001b[0m     execution_options,\n\u001b[1;32m   1504\u001b[0m     compiled_sql,\n\u001b[1;32m   1505\u001b[0m     distilled_params,\n\u001b[1;32m   1506\u001b[0m     elem,\n\u001b[1;32m   1507\u001b[0m     extracted_params,\n\u001b[1;32m   1508\u001b[0m     cache_hit\u001b[39m=\u001b[39;49mcache_hit,\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1510\u001b[0m \u001b[39mif\u001b[39;00m has_events:\n\u001b[1;32m   1511\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_execute(\n\u001b[1;32m   1512\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   1513\u001b[0m         elem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1517\u001b[0m         ret,\n\u001b[1;32m   1518\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py:1862\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1859\u001b[0m             branched\u001b[39m.\u001b[39mclose()\n\u001b[1;32m   1861\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1862\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_dbapi_exception(\n\u001b[1;32m   1863\u001b[0m         e, statement, parameters, cursor, context\n\u001b[1;32m   1864\u001b[0m     )\n\u001b[1;32m   1866\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py:2043\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   2041\u001b[0m     util\u001b[39m.\u001b[39mraise_(newraise, with_traceback\u001b[39m=\u001b[39mexc_info[\u001b[39m2\u001b[39m], from_\u001b[39m=\u001b[39me)\n\u001b[1;32m   2042\u001b[0m \u001b[39melif\u001b[39;00m should_wrap:\n\u001b[0;32m-> 2043\u001b[0m     util\u001b[39m.\u001b[39;49mraise_(\n\u001b[1;32m   2044\u001b[0m         sqlalchemy_exception, with_traceback\u001b[39m=\u001b[39;49mexc_info[\u001b[39m2\u001b[39;49m], from_\u001b[39m=\u001b[39;49me\n\u001b[1;32m   2045\u001b[0m     )\n\u001b[1;32m   2046\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2047\u001b[0m     util\u001b[39m.\u001b[39mraise_(exc_info[\u001b[39m1\u001b[39m], with_traceback\u001b[39m=\u001b[39mexc_info[\u001b[39m2\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py:208\u001b[0m, in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    205\u001b[0m     exception\u001b[39m.\u001b[39m__cause__ \u001b[39m=\u001b[39m replace_context\n\u001b[1;32m    207\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m     \u001b[39mraise\u001b[39;00m exception\n\u001b[1;32m    209\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m     \u001b[39m# credit to\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[39m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[39m# as the __traceback__ object creates a cycle\u001b[39;00m\n\u001b[1;32m    213\u001b[0m     \u001b[39mdel\u001b[39;00m exception, replace_context, from_, with_traceback\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py:1799\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1797\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1798\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1799\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_executemany(\n\u001b[1;32m   1800\u001b[0m             cursor, statement, parameters, context\n\u001b[1;32m   1801\u001b[0m         )\n\u001b[1;32m   1802\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m parameters \u001b[39mand\u001b[39;00m context\u001b[39m.\u001b[39mno_parameters:\n\u001b[1;32m   1803\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\u001b[39m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py:729\u001b[0m, in \u001b[0;36mDefaultDialect.do_executemany\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_executemany\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 729\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecutemany(statement, parameters)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyhive/common.py:91\u001b[0m, in \u001b[0;36mDBAPICursor.executemany\u001b[0;34m(self, operation, seq_of_parameters)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexecute(operation, parameters)\n\u001b[1;32m     90\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_STATE_FINISHED:\n\u001b[0;32m---> 91\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fetch_more()\n\u001b[1;32m     92\u001b[0m \u001b[39mif\u001b[39;00m seq_of_parameters:\n\u001b[1;32m     93\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexecute(operation, seq_of_parameters[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyhive/hive.py:470\u001b[0m, in \u001b[0;36mCursor._fetch_more\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[39massert\u001b[39;00m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_operationHandle \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m), \u001b[39m\"\u001b[39m\u001b[39mShould have an op handle in _fetch_more\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    469\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_operationHandle\u001b[39m.\u001b[39mhasResultSet:\n\u001b[0;32m--> 470\u001b[0m     \u001b[39mraise\u001b[39;00m ProgrammingError(\u001b[39m\"\u001b[39m\u001b[39mNo result set\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    471\u001b[0m req \u001b[39m=\u001b[39m ttypes\u001b[39m.\u001b[39mTFetchResultsReq(\n\u001b[1;32m    472\u001b[0m     operationHandle\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_operationHandle,\n\u001b[1;32m    473\u001b[0m     orientation\u001b[39m=\u001b[39mttypes\u001b[39m.\u001b[39mTFetchOrientation\u001b[39m.\u001b[39mFETCH_NEXT,\n\u001b[1;32m    474\u001b[0m     maxRows\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39marraysize,\n\u001b[1;32m    475\u001b[0m )\n\u001b[1;32m    476\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connection\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mFetchResults(req)\n",
      "\u001b[0;31mProgrammingError\u001b[0m: (pyhive.exc.ProgrammingError) No result set\n[SQL: INSERT INTO TABLE `location` VALUES (%(LocationID)s, %(Borough)s, %(Zone)s, %(service_zone)s)]\n[parameters: ({'LocationID': 1, 'Borough': 'EWR', 'Zone': 'Newark Airport', 'service_zone': 'EWR'}, {'LocationID': 2, 'Borough': 'Queens', 'Zone': 'Jamaica Bay', 'service_zone': 'Boro Zone'}, {'LocationID': 3, 'Borough': 'Bronx', 'Zone': 'Allerton/Pelham Gardens', 'service_zone': 'Boro Zone'}, {'LocationID': 4, 'Borough': 'Manhattan', 'Zone': 'Alphabet City', 'service_zone': 'Yellow Zone'}, {'LocationID': 5, 'Borough': 'Staten Island', 'Zone': 'Arden Heights', 'service_zone': 'Boro Zone'}, {'LocationID': 6, 'Borough': 'Staten Island', 'Zone': 'Arrochar/Fort Wadsworth', 'service_zone': 'Boro Zone'}, {'LocationID': 7, 'Borough': 'Queens', 'Zone': 'Astoria', 'service_zone': 'Boro Zone'}, {'LocationID': 8, 'Borough': 'Queens', 'Zone': 'Astoria Park', 'service_zone': 'Boro Zone'}  ... displaying 10 of 265 total bound parameter sets ...  {'LocationID': 264, 'Borough': 'Unknown', 'Zone': 'NV', 'service_zone': None}, {'LocationID': 265, 'Borough': 'Unknown', 'Zone': None, 'service_zone': None})]\n(Background on this error at: https://sqlalche.me/e/14/f405)"
     ]
    }
   ],
   "source": [
    "# try:\n",
    "df_location.to_sql(\"location\", engine, index=False, if_exists='append')\n",
    "\n",
    "# except Exception as e:  #Want to capture all errors\n",
    "#     print(\"Shiat broke down ...\")\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_to_hive(): \n",
    "#         # load the .csv file data to spark dataframe\n",
    "#         weather = spark.read \\\n",
    "#                     .format(\"parquet\") \\\n",
    "#                     .option(\"header\", \"true\") \\\n",
    "#                     .load(\"../Data/Taxis.parquet\")\n",
    "#         # print a dataframe to the console\n",
    "#         weather.show()\n",
    " \n",
    "#         ####Method 1 - write method ######\n",
    "#         # save dataframe to a Hive table\n",
    "#         weather.write \\\n",
    "#         .format(\"orc\") \\\n",
    "#         .mode(\"overwrite\") \\\n",
    "#         .saveAsTable(\"TaxisDB.weather\")\n",
    " \n",
    "# #Main program starts here\n",
    "# if __name__ == \"__main__\":\n",
    "#         appname = \"ETL pipeline\"\n",
    "#         master = \"local\"\n",
    "#         spark = SparkSession.builder.appName(appname).master(master).enableHiveSupport().getOrCreate()\n",
    "#         load_to_hive()\n",
    "#         spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/12 21:05:26 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "22/07/12 21:05:26 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "22/07/12 21:05:33 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
      "22/07/12 21:05:33 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore mangoru@127.0.1.1\n",
      "22/07/12 21:05:33 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException\n",
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show databases\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
